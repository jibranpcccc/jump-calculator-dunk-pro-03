
# Robots.txt for Dunk Calculator
# Website: https://dunkcalculator.com
# Updated: 2024-05-29

User-agent: *
Allow: /

# Allow all search engines to crawl important pages
Allow: /calculators/
Allow: /vertical-jump-training/
Allow: /measurements/
Allow: /blog/
Allow: /faq
Allow: /about
Allow: /contact
Allow: /dunking-skills/

# Specific instructions for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 2

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 2

User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: PinterestBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: TelegramBot
Allow: /

# Mobile-specific crawlers
User-agent: Googlebot-Mobile
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Image
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Video
Allow: /
Crawl-delay: 1

User-agent: Googlebot-News
Allow: /
Crawl-delay: 1

# Block problematic or resource-intensive bots
User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: SiteAuditBot
Disallow: /

User-agent: MegaIndex
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

# Block access to admin and private areas
Disallow: /admin/
Disallow: /private/
Disallow: /*.pdf$
Disallow: /api/
Disallow: /temp/
Disallow: /cache/
Disallow: /_next/
Disallow: /node_modules/

# Block specific file types that shouldn't be crawled
Disallow: /*.json$
Disallow: /*.xml$
Disallow: /*.txt$
Disallow: /*.log$

# Allow access to CSS, JS, and images for proper rendering
Allow: /assets/
Allow: /*.css
Allow: /*.js
Allow: /*.jpg
Allow: /*.jpeg
Allow: /*.png
Allow: /*.gif
Allow: /*.svg
Allow: /*.webp
Allow: /*.ico
Allow: /*.woff
Allow: /*.woff2
Allow: /fonts/

# Special exceptions for specific files
Allow: /sitemap.xml
Allow: /robots.txt
Allow: /manifest.json

# Sitemap location
Sitemap: https://dunkcalculator.com/sitemap.xml

# Host directive (for some search engines)
Host: https://dunkcalculator.com

# Additional directives for better SEO
# Request cache time for robots.txt (1 day = 86400 seconds)
# This is a non-standard directive but some crawlers respect it
Request-rate: 1/1s
Visit-time: 0600-2300
